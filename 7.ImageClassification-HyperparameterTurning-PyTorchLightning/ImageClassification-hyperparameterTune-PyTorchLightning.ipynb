{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "bf74d2e9-2708-49b1-934b-e0ede342f475"
    }
   },
   "source": [
    "# Training, hyperparameter tune, and deploy with PyTorch Lightning\n",
    "\n",
    "## Introduction:\n",
    "\n",
    "## Prerequisite:\n",
    "* Understand the [architecture and terms](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture) introduced by Azure Machine Learning\n",
    "* install the AML SDK\n",
    "* create a workspace and downlod its configuration file (`config.json`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "c377ea0c-0cd9-4345-9be2-e20fb29c94c3"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import azureml\n",
    "from azureml.core import Workspace\n",
    "from azureml.core import Experiment\n",
    "from azureml.core import ScriptRunConfig\n",
    "from azureml.core import Dataset\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core import Environment\n",
    "from azureml.telemetry import set_diagnostics_collection\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.hyperdrive import RandomParameterSampling, BayesianParameterSampling, BanditPolicy, HyperDriveConfig, PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive import choice, loguniform, uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "edaa7f2f-2439-4148-b57a-8c794c0945ec"
    }
   },
   "outputs": [],
   "source": [
    "# check core SDK version number\n",
    "print('This code run confrimed - SDK version: 1.19.0')\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)\n",
    "\n",
    "set_diagnostics_collection(send_diagnostics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize workspace\n",
    "Initialize a [Workspace](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace) object from the existing workspace you created in the Prerequisites step. `Workspace.from_config()` creates a workspace object from the details stored in `config.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep='\\n')\n",
    "\n",
    "exp = Experiment(workspace=ws, name='ImageClassification-PyTorchLightning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "defe921f-8097-44c3-8336-8af6700804a7"
    }
   },
   "source": [
    "## Connect dataset\n",
    "In order to train on the `cat_dogs` dataset that was created via Azure ML SDK or Portal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.get_by_name(ws, name='cat_dogs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set training cluster - AmlCompute\n",
    "You can create a [compute target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target) for training your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_target = ComputeTarget(workspace=ws, name='gpucluster6')\n",
    "compute_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcurate Count of GPU\n",
    "\n",
    "This is for useful **multi GPU** senario like NC12,24 series.\n",
    "\n",
    "vm_size list\n",
    "https://docs.microsoft.com/en-us/azure/virtual-machines/linux/sizes-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "comp_dict = compute_target.get_status().serialize()\n",
    "vm_size = comp_dict['vmSize']\n",
    "print(vm_size)\n",
    "\n",
    "def get_gpu_count(vm_size):\n",
    "    pattern=r'\\d{1,2}'\n",
    "    s = re.search(pattern, vm_size)\n",
    "    gpu_count = vm_size[s.start():s.end()]\n",
    "    return int(gpu_count) // 6\n",
    "\n",
    "n_gpu = get_gpu_count(vm_size)\n",
    "print('gpu_count:' + str(n_gpu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an environment\n",
    "Define a conda environment YAML file with your training script dependencies and create an Azure ML environment.\n",
    "\n",
    "Reference for-\n",
    "\n",
    "Document:\n",
    "https://docs.microsoft.com/ja-jp/azure/machine-learning/how-to-use-environments#use-a-prebuilt-docker-image\n",
    "\n",
    "base_image:\n",
    "https://github.com/Azure/AzureML-Containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment.from_conda_specification('my_pl', 'environment.yml')\n",
    "# specify a GPU base image\n",
    "env.docker.enabled = True\n",
    "env.docker.base_image = (\n",
    "    \"mcr.microsoft.com/azureml/openmpi3.1.2-cuda10.2-cudnn8-ubuntu18.04\"\n",
    ")"
   ]
  },
  {
   "source": [
    "# Prepare training script\n",
    "\n",
    "Now you will need to create your training script. In this tutorial, the training script is already provided for you at `train.py`. In practice, you should be able to take any custom training script as is and run it with Azure ML without having to modify your code.\n",
    "\n",
    "However, if you would like to use Azure ML's tracking and metrics capabilities, you will have to add a small amount of Azure ML code inside your training script.\n",
    "\n",
    "In `train.py`, we will log some metrics to our Azure ML run. To do so, we will access the Azure ML Run object within the script:\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "script_folder = './script'\n",
    "os.makedirs(script_folder, exist_ok=True)\n",
    "\n",
    "# the training logic is in the train.py file.\n",
    "shutil.copy('./train.py', script_folder)"
   ]
  },
  {
   "source": [
    "# Configure the Single job\n",
    "\n",
    "Create a ScriptRunConfig object to specify the configuration details of your training job, including your training script, environment to use, and the compute target to run on. The following code will configure a single-node PyTorch job."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = [\n",
    "    '--data-folder', dataset.as_mount(),\n",
    "    '--batch-size', 50,\n",
    "    '--epoch', 1,\n",
    "    '--learning-rate', 0.001,\n",
    "    '--momentum', 0.9,\n",
    "    '--model-name', 'resnet',\n",
    "    '--optimizer', 'Adagrad',\n",
    "    '--criterion', 'cross_entropy',\n",
    "    '--gpus', n_gpu,\n",
    "    '--feature_extract', True\n",
    "]\n",
    "\n",
    "'''\n",
    "        '--optimizer': choice('SGD',\n",
    "        \n",
    "        \n",
    "        'Adagrad','Adadelta','Adam','AdamW','SparseAdam', 'Adamax', 'ASGD', 'LBFGS', 'RMSprop', 'Rprop'),\n",
    "        '--criterion': choice('cross_entropy', 'binary_cross_entropy', 'binary_cross_entropy_with_logits', 'poisson_nll_loss', 'hinge_embedding_loss', 'kl_div', 'l1_loss', 'mse_loss', 'margin_ranking_loss', 'multilabel_margin_loss', 'multilabel_soft_margin_loss', 'multi_margin_loss','nll_loss', 'smooth_l1_loss', 'soft_margin_loss')\n",
    "\n",
    "'''\n",
    "\n",
    "config = ScriptRunConfig(\n",
    "                source_directory=script_folder,\n",
    "                script='train.py',\n",
    "                arguments=arguments,\n",
    "                compute_target=compute_target, \n",
    "                max_run_duration_seconds=600, # 10 minutes\n",
    "                environment=env\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit job to run\n",
    "Submit the estimator to the Azure ML experiment to kick off the execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = exp.submit(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor the Run\n",
    "As the Run is executed, it will go through the following stages:\n",
    "1. Preparing: A docker image is created matching the Python environment specified by the TensorFlow estimator and it will be uploaded to the workspace's Azure Container Registry. This step will only happen once for each Python environment -- the container will then be cached for subsequent runs. Creating and uploading the image takes about **5 minutes**. While the job is preparing, logs are streamed to the run history and can be viewed to monitor the progress of the image creation.\n",
    "\n",
    "2. Scaling: If the compute needs to be scaled up (i.e. the AmlCompute cluster requires more nodes to execute the run than currently available), the cluster will attempt to scale up in order to make the required amount of nodes available. Scaling typically takes about **5 minutes**.\n",
    "\n",
    "3. Running: All scripts in the script folder are uploaded to the compute target, data stores are mounted/copied and the `entry_script` is executed. While the job is running, stdout and the `./logs` folder are streamed to the run history and can be viewed to monitor the progress of the run.\n",
    "\n",
    "4. Post-Processing: The `./outputs` folder of the run is copied over to the run history\n",
    "\n",
    "There are multiple ways to check the progress of a running job. We can use a Jupyter notebook widget. \n",
    "\n",
    "**Note: The widget will automatically update ever 10-15 seconds, always showing you the most up-to-date information about the run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also periodically check the status of the run object, and navigate to Azure portal to monitor the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the saved model\n",
    "\n",
    "In the training script, the PyTorch model is saved into two files, `model.dist` and `model.pt`, in the `outputs/models` folder on the gpucluster AmlCompute node. Azure ML automatically uploaded anything written in the `./outputs` folder into run history file store. Subsequently, we can use the `run` object to download the model files. They are under the the `outputs/model` folder in the run history file store, and are downloaded into a local folder named `model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model folder in the current directory\n",
    "os.makedirs('./model', exist_ok=True)\n",
    "\n",
    "for f in run.get_file_names():\n",
    "    if f.startswith('outputs/model'):\n",
    "        output_file_path = os.path.join('./model', f.split('/')[-1])\n",
    "        print('Downloading from {} to {} ...'.format(f, output_file_path))\n",
    "        run.download_file(name=f, output_file_path=output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning by HyperDrive\n",
    "We have trained the model with one set of hyperparameters, now let's how we can do hyperparameter tuning by launching multiple runs on the cluster. First let's define the parameter space using random sampling.\n",
    "\n",
    "1st time: Use **Random Sampling** to understand rough hyperparameter range.\n",
    "\n",
    "2nd time or later: Use** Bayesian Sampling** using 1st job result to more optimize explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BayesianParameterSampling dones't support Eearly Termination Policy\n",
    "# https://docs.microsoft.com/ja-jp/azure/machine-learning/service/how-to-tune-hyperparameters\n",
    "\n",
    "# Use Random Sampling as 1st Phase\n",
    "ps = RandomParameterSampling(\n",
    "    {\n",
    "        '--batch-size': choice(50, 100),\n",
    "        '--epoch': choice(1, 2),\n",
    "        '--learning-rate': loguniform(-4, -1),\n",
    "        '--momentum': loguniform(-3, -1),\n",
    "        '--model-name': choice('resnet', 'alexnet', 'vgg', 'squeezenet', 'densenet', 'inception'),\n",
    "        '--optimizer': choice('SGD','Adagrad','Adadelta','Adam','AdamW','Adamax', 'ASGD', 'RMSprop', 'Rprop'),\n",
    "        '--criterion': choice('cross_entropy')\n",
    "    }\n",
    ")\n",
    "\n",
    "# After Random Sampling finished, try to better hyperparameters using Basyean Sampling\n",
    "'''\n",
    "ps = BayesianParameterSampling(\n",
    "    {\n",
    "        '--batch-size': choice(50, 100, 150, 200, 250, 300),\n",
    "        '--epoch': choice(20, 25, 30, 35),\n",
    "        '--learning-rate': loguniform(-4, -1),\n",
    "        '--momentum': loguniform(-2, -1),\n",
    "        '--model-name': choice('resnet', 'alexnet', 'vgg', 'squeezenet', 'densenet', 'inception'),\n",
    "        '--optimizer': choice('SGD','Adagrad','Adadelta','Adam','AdamW','SparseAdam', 'Adamax', 'ASGD', 'RMSprop', 'Rprop'),\n",
    "        '--criterion': choice('cross_entropy', 'binary_cross_entropy', 'binary_cross_entropy_with_logits', 'poisson_nll_loss', 'hinge_embedding_loss', 'kl_div', 'l1_loss', 'mse_loss', 'margin_ranking_loss', 'multilabel_margin_loss', 'multilabel_soft_margin_loss', 'multi_margin_loss','nll_loss', 'smooth_l1_loss', 'soft_margin_loss')\n",
    "    }\n",
    ")\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will define an early termnination policy. The `BanditPolicy` basically states to check the job every 2 iterations. If the primary metric (defined later) falls outside of the top 10% range, Azure ML terminate the job. This saves us from continuing to explore hyperparameters that don't show promise of helping reach our target metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = BanditPolicy(slack_factor=0.15, evaluation_interval=2, delay_evaluation=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to configure a run configuration object, and specify the primary metric `Accuracy` that's recorded in your training runs. If you go back to visit the training script, you will notice that this value is being logged after every epoch (a full batch set). We also want to tell the service that we are looking to maximizing this value. We also set the number of samples to 20, and maximal concurrent job to 4, which is the same as the number of nodes in our computer cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "arguments = [\n",
    "    '--data-folder', dataset.as_mount(),\n",
    "    '--gpus', n_gpu,\n",
    "    '--feature_extract', True\n",
    "]\n",
    "\n",
    "config = ScriptRunConfig(\n",
    "                source_directory=script_folder,\n",
    "                script='train.py',\n",
    "                arguments=arguments,\n",
    "                compute_target=compute_target, \n",
    "                max_run_duration_seconds=600, # 10 minutes\n",
    "                environment=env\n",
    "                )\n",
    "\n",
    "hdc = HyperDriveConfig(run_config=config, \n",
    "                       hyperparameter_sampling=ps, \n",
    "                       policy=policy, # Comment out this line for Baysian Sampling\n",
    "                       primary_metric_name='Accuracy', \n",
    "                       primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n",
    "                       max_total_runs=180,\n",
    "                       max_concurrent_runs=4,\n",
    "                       max_duration_minutes=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's launch the hyperparameter tuning job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdr = exp.submit(config=hdc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a run history widget to show the progress. Be patient as this might take a while to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(hdr).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdr.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find and register best model\n",
    "When all the jobs finish, we can find out the one that has the highest accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run = hdr.get_best_run_by_primary_metric()\n",
    "print(best_run.get_details()['runDefinition']['arguments'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's list the model files uploaded during the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_run.get_file_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then register the folder (and all files in it) as a model named `dog_cats_imageclassification_pytourch` under the workspace for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_run.register_model(model_name='dog_cats_imageclassification_pytourch', model_path='outputs/model')"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "maxluk"
   }
  ],
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.12 64-bit ('azureml-pl-dev': conda)",
   "metadata": {
    "interpreter": {
     "hash": "3b76e808fc31d90937dc810a743553d1c496efcbf818aecb65d834a90cc387f9"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "msauthor": "maxluk"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}